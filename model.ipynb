{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/features.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "Y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# log_reg = LogisticRegression(max_iter=150)\n",
    "# log_reg.fit(X, Y)\n",
    "# print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=95, criterion='entropy', random_state=25)\n",
    "rf.fit(X, Y)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test/features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.iloc[:, :-1].values\n",
    "Y_test = test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy  0.917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(Y_test, Y_pred)\n",
    "print('model accuracy ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06490406, 0.06183015, 0.09033437, 0.01523445, 0.05923563,\n",
       "       0.04719966, 0.04686638, 0.26975824, 0.15236471, 0.1286733 ,\n",
       "       0.06359906])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/model_91_7_latest.mu']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "joblib.dump(rf, './models/model_91_7_latest.mu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "\n",
    "# model = joblib.load('./models/model_90_7.mu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import predict as predict\n",
    "import algo as algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sardinas_patterson import sardinas_patterson\n",
    "\n",
    "\n",
    "sardinas_patterson({'000010','010110','001','00','110','101011','0011100','1110','1100101','00011'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'algo' from 'c:\\\\Users\\\\Mialisoa\\\\ITU\\\\S6\\\\codage\\\\algo\\\\ml\\\\algo.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(predict)\n",
    "importlib.reload(algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(predict)\n",
    "importlib.reload(algo)\n",
    "data_nante = [\n",
    "    {'1100111', '0010100', '010', '011', '1100', '110'},\n",
    "{'11', '0011111', '10010', '101111', '001101'},\n",
    "{'1110100', '1'},\n",
    "{'11101', '111', '1000110', '10110', '01', '1001011', '010', '01001'},\n",
    "{'01110', '1011000', '100', '1', '10', '011000', '1010010', '1001'},\n",
    "{'01001', '1', '1101111', '11110'},\n",
    "]\n",
    "\n",
    "nante_vrai = [1,1,1,0,0,0]\n",
    "\n",
    "nante_predict = predict.predict_list(rf, data_nante)\n",
    "print('tests accuracy')\n",
    "accuracy_score(nante_vrai, nante_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score tsy code\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9019019019019019"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(algo)\n",
    "test_code = pd.read_csv('./data/test/code.csv')\n",
    "\n",
    "codes = algo.format_to_set(test_code)\n",
    "    \n",
    "    # CODE, raha tsy code d 0\n",
    "test_y_vrai = [1 for i in range(len(codes))]\n",
    "test_y_predict = predict.predict_list(rf, codes)\n",
    "print('score tsy code')\n",
    "accuracy_score(test_y_vrai, test_y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok  5  /  13\n"
     ]
    }
   ],
   "source": [
    "langages = [\n",
    "    {'0100011', '011011', '001', '0110000', '0101110', '101', '0000011', '00101', '00110'},\n",
    "    {'0101000', '0100', '1100011', '0110', '10111', '01', '0110110', '110101'},\n",
    "    {'000001', '1', '100000', '1011100', '000000'},\n",
    "    {'10100', '10010', '11100', '10'},\n",
    "    {'00', '0000', '1000001'},\n",
    "    {'0', '000', '11000'},\n",
    "    {'1011101', '10101', '1011', '0111011'},\n",
    "    {'1101', '000', '00'},\n",
    "    {'1101011', '010001', '1010', '10000', '0'},\n",
    "    {'00001', '000', '00', '1100011', '1100101'},\n",
    "    {'001', '110110', '110', '10'},\n",
    "    {'00', '10', '01011', '10011', '10111'},\n",
    "    {'111001', '10011', '00', '0000', '0000111'}\n",
    "]\n",
    "\n",
    "# langages = [\n",
    "#     \"011;1101010;010;00001;100;0000110\",\n",
    "# \"011;011001;00101;000111;0000;0100\",\n",
    "# \"1111000;001111;110010;10110;0110;111\",\n",
    "# \"1001010;100;100111;11;0110110;011101;0;0111101\",\n",
    "# \"000;101;111110;01;0000;0;1\",\n",
    "# \"010100;11;00;0000;0001100;1101000;0101010;0010111\",\n",
    "# \"101;0101;0101111;01;11001;00;11;101011;0011110;0\",\n",
    "# ]\n",
    "#\n",
    "ok = 0\n",
    "for langage in langages :\n",
    "    prediction = predict.predict_langage(rf, langage)\n",
    "    # #\n",
    "    sardinas = sardinas_patterson(langage)\n",
    "\n",
    "    if(sardinas == prediction) :\n",
    "        ok = ok +1\n",
    "    # print('L:', langage, ' S: ', sardinas, ' P: ', prediction)\n",
    "\n",
    "print('ok ', ok, ' / ', len(langages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred': 1, 'verdict': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(predict)\n",
    "predict.predict(rf, \"101010;110001;0111;11;11001;1010100;0010000\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
